{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MArVLKki0152"
      },
      "source": [
        "# CS231a PSET 3 Problem 5: Optical Flow\n",
        "\n",
        "Use this notebook to run the last portion of problem 5 of PSET 3. Instead of connecting to your Drive, you can just upload using the files tab on the right. If you have issues with the upload, you can try the following instead:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "WK8W3gASlXDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVNdV6eL0157"
      },
      "source": [
        "## Set up ml4a and enable GPU\n",
        "\n",
        "First, enable using the GPU (`Runtime` > `Change runtime type`), and then run the following cell to install ml4a and its dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itjpECd20157"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip3 install --quiet ml4a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2NOCV2I0159"
      },
      "source": [
        "## Get optical flow between images\n",
        "\n",
        "First we load two images, which happen to be consecutive frames of a movie. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install Pillow"
      ],
      "metadata": {
        "id": "uvChkklWH1Ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcxaWHaV0159"
      },
      "outputs": [],
      "source": [
        "from ml4a import image\n",
        "from PIL import Image\n",
        "from ml4a.canvas import canvas\n",
        "from ml4a.models import flownet\n",
        "\n",
        "globeimg1 = Image.open('rgb01.png')\n",
        "globeimg2 = Image.open('rgb02.png')\n",
        "\n",
        "image.display([globeimg1, globeimg2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al0Jxk6J015_"
      },
      "outputs": [],
      "source": [
        "# get flow from img1 to img2\n",
        "flow = flownet.run(globeimg1, globeimg2) \n",
        "\n",
        "# blurring the flow reduces any high-frequency noise in the raw flowmap\n",
        "flow = flownet.blur(flow, blur_times=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ-fQbYG016A"
      },
      "source": [
        "It's easier to visualize the flowmap if we map it to color. Then we can display it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFRf-jrV016A"
      },
      "outputs": [],
      "source": [
        "rgb_flow = flownet.run(globeimg1, globeimg2, to_rgb=True) \n",
        "image.display(rgb_flow)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One way to see what the optical flow does is to use the flowmap on one of the images to reconstruct the other. We can do that with `canvas.map_image`."
      ],
      "metadata": {
        "id": "-BXbFXHqWEJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_1to2 = flownet.flow_to_mapping(-flow)\n",
        "mapping_2to1 = flownet.flow_to_mapping(flow)\n",
        "\n",
        "globeimg2_reconstructed = canvas.map_image(globeimg1, mapping_1to2)\n",
        "globeimg1_reconstructed = canvas.map_image(globeimg2, mapping_2to1)\n",
        "\n",
        "image.display(globeimg2, title=\"image 2\")\n",
        "image.display(globeimg2_reconstructed, title=\"image 2 reconstructed from image 1 + flow\")"
      ],
      "metadata": {
        "id": "4iEdfctxNR8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the steps above for the other two pairs of images"
      ],
      "metadata": {
        "id": "lPGx3I4ZWJ9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "globeimg3 = Image.open('rgb04.png')\n",
        "globeimg4 = Image.open('rgb06.png')\n",
        "\n",
        "image.display([globeimg3, globeimg4])"
      ],
      "metadata": {
        "id": "gx845Mp3NbyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get flow from img1 to img2\n",
        "flow = flownet.run(globeimg3, globeimg4) \n",
        "\n",
        "# blurring the flow reduces any high-frequency noise in the raw flowmap\n",
        "flow = flownet.blur(flow, blur_times=2)\n",
        "\n",
        "rgb_flow = flownet.run(globeimg3, globeimg4, to_rgb=True) \n",
        "image.display(rgb_flow)"
      ],
      "metadata": {
        "id": "JeStLTBkN1NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping_1to2 = flownet.flow_to_mapping(-flow)\n",
        "mapping_2to1 = flownet.flow_to_mapping(flow)\n",
        "\n",
        "globeimg4_reconstructed = canvas.map_image(globeimg3, mapping_1to2)\n",
        "globeimg3_reconstructed = canvas.map_image(globeimg4, mapping_2to1)\n",
        "\n",
        "image.display(globeimg4, title=\"image 2\")\n",
        "image.display(globeimg4_reconstructed, title=\"image 2 reconstructed from image 1 + flow\")"
      ],
      "metadata": {
        "id": "_qO6PbJAN3Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chairimg1 = Image.open('frame_1_chairs.png').convert('RGB')\n",
        "chairimg2 = Image.open('frame_2_chairs.png').convert('RGB')\n",
        "\n",
        "image.display([chairimg1, chairimg2])"
      ],
      "metadata": {
        "id": "_Pb0kwNbJJ1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get flow from img1 to img2\n",
        "flow = flownet.run(chairimg1, chairimg2) \n",
        "\n",
        "# blurring the flow reduces any high-frequency noise in the raw flowmap\n",
        "flow = flownet.blur(flow, blur_times=10)\n",
        "\n",
        "rgb_flow = flownet.run(chairimg1, chairimg2, to_rgb=True) \n",
        "image.display(rgb_flow)"
      ],
      "metadata": {
        "id": "olIAvC1MJTvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GARUo2V016C"
      },
      "outputs": [],
      "source": [
        "mapping_1to2 = flownet.flow_to_mapping(-flow)\n",
        "mapping_2to1 = flownet.flow_to_mapping(flow)\n",
        "\n",
        "chairimg2_reconstructed = canvas.map_image(chairimg1, mapping_1to2)\n",
        "chairimg1_reconstructed = canvas.map_image(chairimg2, mapping_2to1)\n",
        "\n",
        "image.display(chairimg2, title=\"image 2\")\n",
        "image.display(chairimg2_reconstructed, title=\"image 2 reconstructed from image 1 + flow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's it! Just download these images to include in your report, and compare to the results from the previous part."
      ],
      "metadata": {
        "id": "g_MHxFDflhxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit: this notebook is dervied from [this one](https://colab.research.google.com/github/ml4a/ml4a/blob/master/examples/models/FlowNetPytorch.ipynb)"
      ],
      "metadata": {
        "id": "cEmKDYr5gDdZ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "FlowNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}